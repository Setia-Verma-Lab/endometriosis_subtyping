configfile: 'config_pheno.yaml'

EMERGE_ICD_PHECODE = '/project/ritchie01/datasets/eMERGE/eMERGE_III_pheno_organized/data_download_02_13_2020/gwas_phecode_20190913_0.csv'
EMERGE_DEMO = '/project/ritchie01/datasets/eMERGE/eMERGE_III_pheno_organized/data_download_02_13_2020/demo_gwas_20190909.csv'
EMERGE_ANC_PREFIX = '/project/ritchie01/datasets/eMERGE/eMERGE_III_Imputed_UW/V2_wHarvard/R-squared_summary_and_accessory_files/kmeans_pca_genetic_ancestry.'
EMERGE_PCS = '/project/ritchie01/datasets/eMERGE/eMERGE_III_Imputed_UW/V2_wHarvard/R-squared_summary_and_accessory_files/chr1-22.merged.maf.05.LD_1000_50_.7_pruned.no_tri.plink.pca-approx.eigenvec'
EMERGE_BMI = '/project/ritchie01/datasets/eMERGE/eMERGE_III_pheno_organized/data_download_02_13_2020/bmi_gwas_20190913.csv'
EMERGE_PROCEDURES = '/project/ritchie01/datasets/eMERGE/eMERGE_III_pheno_organized/data_pull_09_30_2022/CPT_GWAS.csv'
EMERGE_RELATEDS = '/project/ritchie01/datasets/eMERGE/eMERGE_III_Imputed_UW/V2_wHarvard/R-squared_summary_and_accessory_files/V2_all_pihat0.25_related_samples_to_drop.txt'
EMERGE_LABS_PREFIX = '/project/ritchie/datasets/eMERGE/eMERGE_III_pheno_organized/data_pull_09_30_2022/Labs_By_PMBB_2.2_Name/'

PMBB_COVAR = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.2/PMBB-Release-2020-2.2_phenotype_covariates.txt'
PMBB_PHECODE = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.1/PMBB-Release-2020-2.1_phenotype_phecode.txt'
PMBB_ICD = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.2/PMBB-Release-2020-2.2_phenotype_icd.txt'
PMBB_ANC = '/project/PMBB/PMBB-Release-2020-2.0/Genotype/PCA/PMBB-Release-2020-2.0_genetic_genotype_ancestries.txt'
PMBB_BMI = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.2/PMBB-Release-2020-2.2_phenotype_vitals-BMI.txt'
PMBB_BP = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.2/PMBB-Release-2020-2.2_phenotype_vitals-BP.txt'
PMBB_PROCEDURES = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.2/PMBB-Release-2020-2.2_phenotype_procedures.txt'
PMBB_LABS_PREFIX = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.2/PMBB-Release-2020-2.2_phenotype_labs-'
PMBB_RELATEDS = '/project/PMBB/PMBB-Release-2020-2.0/Imputed/Relatedness/PMBB-Release-2020-2.0_genetic_imputed-topmed-r2_relateds_droplist.txt'

PMBB_ICD_23 = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.3/PMBB-Release-2020-2.3_phenotype_icd.txt'
PMBB_BMI_23 = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.3/PMBB-Release-2020-2.3_phenotype_vitals-BMI.txt'
PMBB_BP_23 = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.3/PMBB-Release-2020-2.3_phenotype_vitals-BP.txt'
PMBB_PROCEDURES_23 = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.3/PMBB-Release-2020-2.3_phenotype_procedures.txt'
PMBB_LABS_PREFIX_23 = '/project/PMBB/PMBB-Release-2020-2.0/Phenotype/2.3/PMBB-Release-2020-2.3_phenotype_labs-'

UKBB_ICD9 = '/project/ritchie01/datasets/UKBiobank/phenotype/ICD_codes/ukb26446.icd9.long.format'
UKBB_ICD10 = '/project/ritchie01/datasets/UKBiobank/phenotype/ICD_codes/ukb26446.icd10.long.format'
UKBB_FIELDS = '/project/ritchie01/datasets/UKBiobank/phenotype/ukb43665/ukb43665.tab'

CURRENT_YEAR = 2022.5

def get_all_icd_codes(ukbb=False):
    all_icd = []

    for pheno in config['pheno_defs']:
        for icd_key in ['icd10_cases', 'icd10_exclude', 'icd9_cases', 'icd9_exclude']:
            if icd_key in config['pheno_defs'][pheno].keys():
                all_icd.extend(config['pheno_defs'][pheno][icd_key])

    if not ukbb:
        all_icd_re = [code.replace('.', '\.').replace('*', '.') for code in all_icd]
    else:
        all_icd_re = [code.replace('.', '').replace('*', '.') for code in all_icd]

    return all_icd, all_icd_re

def get_all_phecodes():
    all_phecodes = []

    for pheno in config['pheno_defs']:
        for phecode_key in ['phecode_cases', 'phecode_exclude']:
            if phecode_key in config['pheno_defs'][pheno].keys():
                all_phecodes.extend(config['pheno_defs'][pheno][phecode_key])

    all_phecode_re = [code.replace('.','\.').replace('*','.') for code in all_phecodes]

    return all_phecodes, all_phecode_re

def shorten_codes_long(long_df, code_regex, code_col, np, original_codes):

    code_map = {}

    shortened_search_table = long_df.copy()
    first_char = list(set([code[:2] for code in code_regex]))

    shortened_search_table = shortened_search_table[shortened_search_table[code_col].str[:2].isin(first_char)]
    mask = np.zeros(len(shortened_search_table)).astype(bool)

    print(code_col, end=': ', flush=True)
    for i, code in enumerate(code_regex):
        print(code, end=' ', flush=True)
        match = shortened_search_table[code_col].str.match(code).fillna(False).values
        code_map[original_codes[i]] = sorted(list(shortened_search_table.loc[match][code_col].unique()))

        mask = mask | match

    print('')
    return shortened_search_table[mask], code_map

def add_phenos_from_matrix(pheno_def, big_matrix, code_map, pheno_df, np, count_matrix):
    for pheno in config['pheno_defs']:
        pheno_col = pheno + '_' + pheno_def
        if pheno_def + '_cases' in config['pheno_defs'][pheno].keys():
            print(pheno_col)
            pheno_df[pheno_col] = 0
            pheno_codes = []
            for code in config['pheno_defs'][pheno][pheno_def + '_cases']:
                pheno_codes.extend(code_map[code])
            pheno_codes = [c for c in pheno_codes if c in big_matrix.columns]
            pheno_matrix = big_matrix[pheno_codes].dropna(how='all')
            age_at_dx = pheno_matrix.min(axis=1)
            pheno_df.loc[age_at_dx.index, pheno_col + '_age@dx'] = age_at_dx
            pheno_df.loc[age_at_dx.index, pheno_col] = 1
            pheno_df.loc[count_matrix.index, pheno_col + '_dx_ct'] = count_matrix[pheno_codes].sum(axis=1)
            pheno_df[pheno_col + '_dx_ct'] = pheno_df[pheno_col + '_dx_ct'].fillna(0)
            if pheno_def + '_exclude' in config['pheno_defs'][pheno].keys():
                exclude_codes = []
                for code in config['pheno_defs'][pheno][pheno_def + '_exclude']:
                    exclude_codes.extend(code_map[code])
                exclude_matrix = big_matrix[exclude_codes].dropna(how='all')
                pheno_df.loc[exclude_matrix.index, pheno_col + '_age@dx'] = np.nan
                pheno_df.loc[exclude_matrix.index, pheno_col] = np.nan

def add_union_phenos(pheno_df, np):
    all_pheno_cols = []
    for pheno in config['pheno_defs']:
        pheno_cols = [c for c in pheno_df.columns if c in [pheno + '_icd9', pheno + '_icd10', pheno + '_phecode']]
        all_pheno_cols.extend(pheno_cols)
        pheno_df[pheno] = pheno_df[pheno_cols].sum(axis=1,skipna=False)
        pheno_df.loc[pheno_df[pheno] > 1, pheno] = 1

        pheno_age_cols = [c for c in pheno_df.columns if c in [pheno + '_icd9_age@dx', pheno + '_icd10_age@dx', pheno + '_phecode_age@dx']]
        pheno_df[pheno + '_age@dx'] = pheno_df[pheno_age_cols].min(axis=1, skipna=True)
        pheno_df.loc[pheno_df[pheno] != 1, pheno + '_age@dx'] = np.nan

        all_pheno_cols.append(pheno + '_icd')

        icd_cols = [c for c in pheno_df.columns if c in [pheno + '_icd9', pheno + '_icd10']]
        pheno_df[pheno + '_icd'] = pheno_df[icd_cols].sum(axis=1,skipna=False)
        pheno_df.loc[pheno_df[pheno + '_icd'] > 1, pheno + '_icd'] = 1

        icd_age_cols = [c for c in pheno_df.columns if c in [pheno + '_icd9_age@dx', pheno + '_icd10_age@dx']]
        pheno_df[pheno + '_icd_age@dx'] = pheno_df[icd_age_cols].min(axis=1,skipna=True)
        pheno_df.loc[pheno_df[pheno + '_icd'] != 1, pheno + '_icd_age@dx'] = np.nan

        all_pheno_cols.append(pheno)
    return sorted(all_pheno_cols)

rule make_emerge_pheno_covars:
    output:
        pheno_table='Pheno/eMERGE_pheno_covars.csv',
        counts=expand('Pheno/eMERGE_counts_{anc}.csv', anc=[a for a in config['ancestries'] if a in ['EUR', 'AFR', 'ASIAN']]),
        maps=expand('Pheno/eMERGE_{type}.json', type=['ICD_codes', 'phecodes']),
        pheno_table_long='Pheno/eMERGE_phenotypes_long.csv',
    params:
        config['pheno_defs'],
        config['keep_covars'],
        config['keep_PCs'],
        config['ancestries']
    resources: mem_mb=25000
    run:
        import pandas as pd
        import numpy as np
        import json
        import sys

        eMERGE = pd.read_csv(EMERGE_DEMO, index_col='SUBJECT_ID')
        print(eMERGE)

        print('Start')
        all_icd, all_icd_re = get_all_icd_codes()
        # all_phecodes, all_phecode_re = get_all_phecodes()

        print(EMERGE_ICD_PHECODE)
        ICD_PHECODE = pd.read_csv(EMERGE_ICD_PHECODE, dtype={'SUBJECT_ID': int, 'ICD_CODE': str, 'ICD_FLAG': str}, nrows=None)
        ICD_PHECODE['AGE_AT_OBSERVATION'] = pd.to_numeric(ICD_PHECODE['AGE_AT_OBSERVATION'], errors='coerce')
        ICD_PHECODE = ICD_PHECODE.dropna(subset=['AGE_AT_OBSERVATION', 'ICD_CODE'], how='all')
        ICD_PHECODE = ICD_PHECODE.dropna(subset=['AGE_AT_OBSERVATION'])
        ICD_PHECODE = ICD_PHECODE.sort_values(by='AGE_AT_OBSERVATION')
        print(ICD_PHECODE)
        if 'PHECODE' not in ICD_PHECODE.columns:
            ICD_PHECODE['PHECODE'] = np.nan
        print(ICD_PHECODE)

        last_ICD_age = ICD_PHECODE.drop_duplicates(subset='SUBJECT_ID', keep='last').set_index('SUBJECT_ID')['AGE_AT_OBSERVATION']
        # ICD_PHECODE = ICD_PHECODE.drop_duplicates(subset=['SUBJECT_ID', 'ICD_CODE'], keep='first', ignore_index=True)
        print(ICD_PHECODE)

        icd_keep_table, icd_map = shorten_codes_long(ICD_PHECODE, all_icd_re, 'ICD_CODE', np, all_icd)
        # phecode_mask, phecode_map = shorten_codes_long(ICD_PHECODE, all_phecode_re, 'PHECODE', np, all_phecodes)
        # ICD_PHECODE = ICD_PHECODE[icd_mask | phecode_mask]
        ICD_PHECODE = icd_keep_table.copy()
        print(ICD_PHECODE)

        inverted_icd_map = {}
        for condition_code, codes in icd_map.items():
            conditions = []
            for condition, defs in config['pheno_defs'].items():
                if 'icd10_cases' in defs.keys():
                    case_codes = [c for c in defs['icd10_cases']]
                    if 'icd9_cases' in defs.keys():
                        case_codes.extend(defs['icd9_cases'])
                elif 'icd9_cases' in defs.keys():
                    case_codes = [c for c in defs['icd9_cases']]
                if condition_code in case_codes:
                    conditions.append(condition)
            conditions = ':'.join(conditions)
            for code in codes:
                if code not in inverted_icd_map.keys():
                    inverted_icd_map[code] = conditions
                else:
                    inverted_icd_map[code] += ':' + conditions

        inverted_phecode_map = {}
        phecode_map = {}
        for condition, codes in phecode_map.items():
            for code in codes:
                if code not in inverted_phecode_map.keys():
                    inverted_phecode_map[code] = condition
                else:
                    inverted_phecode_map[code] += ':' + condition

        ICD_PHECODE['ICD_CONDITIONS'] = ICD_PHECODE['ICD_CODE'].replace(inverted_icd_map)
        ICD_PHECODE['ICD_CONDITIONS'] = ICD_PHECODE['ICD_CONDITIONS'].mask(~ICD_PHECODE['ICD_CODE'].isin(inverted_icd_map.keys()))
        ICD_PHECODE['PHECODE_CONDITIONS'] = ICD_PHECODE['PHECODE'].replace(inverted_phecode_map)
        ICD_PHECODE['PHECODE_CONDITIONS'] = ICD_PHECODE['PHECODE_CONDITIONS'].mask(~ICD_PHECODE['PHECODE'].isin(inverted_icd_map.keys()))

        print(ICD_PHECODE)
        ICD_PHECODE.to_csv(output.pheno_table_long, index=False)

        json.dump(icd_map, open('Pheno/eMERGE_ICD_codes.json','w+'))
        json.dump(phecode_map, open('Pheno/eMERGE_phecodes.json','w+'))

        pheno_df = pd.DataFrame(index=eMERGE.index)
        for icd_version in ['9', '10']:
            ICD_matrix = ICD_PHECODE[ICD_PHECODE['ICD_FLAG'] == icd_version].dropna(subset=['ICD_CODE']).drop_duplicates(subset=['SUBJECT_ID', 'ICD_CODE']).pivot(index='SUBJECT_ID', columns='ICD_CODE', values='AGE_AT_OBSERVATION').sort_index()
            ICD_counts = ICD_PHECODE[ICD_PHECODE['ICD_FLAG'] == icd_version].dropna(subset=['ICD_CODE']).pivot_table(index='SUBJECT_ID', columns='ICD_CODE', values='AGE_AT_OBSERVATION', aggfunc='count').sort_index().fillna(0)
            print(ICD_counts)
            print(ICD_counts.max().max())
            ICD_matrix = ICD_matrix.sort_index()
            ICD_matrix = ICD_matrix.loc[ICD_matrix.index.intersection(eMERGE.index)]
            if len(ICD_matrix) == 0:
                continue
            add_phenos_from_matrix('icd' + icd_version, ICD_matrix, icd_map, pheno_df, np, ICD_counts)

        print(pheno_df)
        PHECODE_matrix = ICD_PHECODE.dropna(subset=['PHECODE']).drop_duplicates(subset=['SUBJECT_ID', 'PHECODE']).pivot(index='SUBJECT_ID', columns='PHECODE', values='AGE_AT_OBSERVATION').sort_index()
        PHECODE_counts = ICD_PHECODE.dropna(subset=['PHECODE']).pivot_table(index='SUBJECT_ID', columns='PHECODE', values='AGE_AT_OBSERVATION', aggfunc='count').sort_index().fillna(0)
        PHECODE_matrix = PHECODE_matrix.sort_index()
        PHECODE_matrix = PHECODE_matrix.loc[PHECODE_matrix.index.intersection(eMERGE.index)]

        if len(PHECODE_matrix) > 0:
            add_phenos_from_matrix('phecode', PHECODE_matrix, phecode_map, pheno_df, np, PHECODE_counts)

        all_pheno_cols = add_union_phenos(pheno_df, np)

        if 'AGE' in config['keep_covars']:
            pheno_df['CURRENT_AGE'] = 2020 - eMERGE['YEAR_BIRTH']
            for pheno in config['pheno_defs']:
                pheno_df['AGE_' + pheno] = pheno_df['CURRENT_AGE'].copy()
                pheno_df['AGE_' + pheno].update(last_ICD_age)
                pheno_df['AGE_' + pheno].update(pheno_df[pheno + '_age@dx'])

        if 'SEX' in config['keep_covars']:
            pheno_df['SEX'] = eMERGE['SEX'].replace({'C46109': 'Male', 'C46110': 'Female', '.': np.nan})

        if 'BMI' in config['keep_covars']:
            print('Adding BMI...')
            bmi = pd.read_csv(EMERGE_BMI, nrows=None)
            # bmi = bmi[bmi['MEASUREMENT_CONCEPT_ID'] == 3038553]
            # print(bmi)
            bmi['AGE_AT_OBSERVATION'] = pd.to_numeric(bmi['AGE_AT_OBSERVATION'], errors='coerce')
            bmi['BODY_MASS_INDEX'] = pd.to_numeric(bmi['BODY_MASS_INDEX'], errors='coerce')
            print(bmi)
            bmi = bmi.dropna(subset=['AGE_AT_OBSERVATION'])
            print(bmi)
            bmi = bmi.sort_values(by='AGE_AT_OBSERVATION').dropna(subset='BODY_MASS_INDEX')
            first_bmi = bmi.drop_duplicates(subset='SUBJECT_ID', keep='first').set_index('SUBJECT_ID')['BODY_MASS_INDEX']
            last_bmi = bmi.drop_duplicates(subset='SUBJECT_ID', keep='last').set_index('SUBJECT_ID')['BODY_MASS_INDEX']
            mean_bmi = bmi.groupby('SUBJECT_ID')['BODY_MASS_INDEX'].mean()
            median_bmi = bmi.groupby('SUBJECT_ID')['BODY_MASS_INDEX'].median()

            pheno_df['BMI_first'] = first_bmi.reindex(pheno_df.index)
            pheno_df['BMI_last'] = last_bmi.reindex(pheno_df.index)
            pheno_df['BMI_mean'] = mean_bmi.reindex(pheno_df.index)
            pheno_df['BMI_median'] = median_bmi.reindex(pheno_df.index)

        print(pheno_df)

        if config['keep_PCs'] > 0:
            pcs = pd.read_table(EMERGE_PCS, index_col='FID')
            keep_cols = ['PC' + str(i) for i in range(1, min(11, config['keep_PCs'] + 1))]
            pheno_df = pheno_df.merge(pcs[keep_cols], left_index=True, right_index=True)

        print(pheno_df)

        suffix_map = {'AFR': 'african', 'EUR': 'european', 'ASIAN': 'asian'}

        print(config['ancestries'])

        pheno_df['ANCESTRY'] = np.nan
        for ancestry in config['ancestries']:
            if ancestry in suffix_map.keys():
                suffix = suffix_map[ancestry]
                ids = [int(i) for i in open(EMERGE_ANC_PREFIX + suffix, 'r').read().splitlines()]
                pheno_df.loc[pheno_df.index.intersection(ids), 'ANCESTRY'] = ancestry

        pheno_df.index.name = 'SUBJID'
        for anc, subDF in pheno_df.groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[all_pheno_cols].apply(lambda x: x.fillna(-9).value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/eMERGE_counts_' + anc + '.csv')

        relateds = open(EMERGE_RELATEDS).read().splitlines()
        pheno_df['Related_to_Drop']  = 0
        pheno_df.loc[pheno_df.index.astype(str).isin(relateds), 'Related_to_Drop'] = 1

        pheno_df = pheno_df[pheno_df['ANCESTRY'].isin(config['ancestries'])]
        print('')
        print(pheno_df)
        pheno_df.to_csv(output.pheno_table)

rule make_pmbb_pheno_covars:
    output:
        pheno_table='Pheno/PMBB_pheno_covars.csv',
        counts=expand('Pheno/PMBB_counts_{anc}.csv', anc=[a for a in config['ancestries'] if a in ['EUR', 'AFR', 'EAS', 'SAS', 'AMR']]),
        maps=expand('Pheno/PMBB_{type}.json', type=['ICD_codes', 'phecodes']),
        pheno_table_long='Pheno/PMBB_phenotypes_long.csv'
    params:
        config['pheno_defs'],
        config['keep_covars'],
        config['keep_PCs'],
        config['ancestries']
    resources: mem_mb=12000
    run:
        import pandas as pd
        import numpy as np
        from datetime import datetime
        import json
        import sys

        print('Start')

        PMBB = pd.read_table(PMBB_COVAR, index_col='PMBB_ID', parse_dates=['Birth_date_SHIFT'])
        PMBB['CURRENT_AGE'] = (datetime(2022,6,1) - PMBB['Birth_date_SHIFT']).dt.days / 365.25
        print(PMBB)

        all_icd, all_icd_re = get_all_icd_codes()
        all_phecodes, all_phecode_re = get_all_phecodes()

        ICD = pd.read_table(PMBB_ICD, dtype={'CODE': str}, parse_dates=['condition_start_date'], nrows=None)
        ICD = ICD[ICD['CODE_STANDARD_NAME'] != 'None']
        PHECODE = pd.read_table(PMBB_PHECODE, dtype={'phecode': str}, parse_dates=['ENC_DATE_SHIFT'], nrows=None)
        print(ICD)
        print(PHECODE)
        ICD = ICD.sort_values(by='condition_start_date')
        PHECODE = PHECODE.sort_values(by='ENC_DATE_SHIFT')

        last_ICD_date = ICD.drop_duplicates(subset='PMBB_ID', keep='last').set_index('PMBB_ID')['condition_start_date']
        ICD = ICD.drop_duplicates(subset=['PMBB_ID', 'CODE'], keep='first', ignore_index=True)
        PHECODE = PHECODE.drop_duplicates(subset=['PMBB_ID', 'phecode'], keep='first', ignore_index=True)
        print(ICD)
        print(PHECODE)

        ICD_new, icd_map = shorten_codes_long(ICD, all_icd_re,'CODE', np, all_icd)
        print(ICD_new)
        ICD = ICD_new.copy()

        PHECODE_new, phecode_map = shorten_codes_long(PHECODE, all_phecode_re, 'phecode', np, all_phecodes)
        PHECODE = PHECODE_new.copy()
        print(ICD)
        print(PHECODE)
        json.dump(icd_map, open('Pheno/PMBB_ICD_codes.json','w+'))
        json.dump(phecode_map, open('Pheno/PMBB_phecodes.json','w+'))

        inverted_icd_map = {}
        for condition_code, codes in icd_map.items():
            conditions = []
            for condition, defs in config['pheno_defs'].items():
                if 'icd10_cases' in defs.keys():
                    case_codes = [c for c in defs['icd10_cases']]
                    if 'icd9_cases' in defs.keys():
                        case_codes.extend(defs['icd9_cases'])
                elif 'icd9_cases' in defs.keys():
                    case_codes = [c for c in defs['icd9_cases']]
                if condition_code in case_codes:
                    conditions.append(condition)
            conditions = ':'.join(conditions)
            for code in codes:
                if code not in inverted_icd_map.keys():
                    inverted_icd_map[code] = conditions
                else:
                    inverted_icd_map[code] += ':' + conditions

        ICD['ICD_CONDITIONS'] = ICD['CODE'].replace(inverted_icd_map)
        ICD['ICD_CONDITIONS'] = ICD['ICD_CONDITIONS'].mask(~ICD['CODE'].isin(inverted_icd_map.keys()))
        pd.concat([ICD, PHECODE]).to_csv(output.pheno_table_long, index=False)

        pheno_df = pd.DataFrame(index=PMBB.index)
        for icd_version in ['9', '10']:
            ICD_matrix = ICD[ICD['CODE_STANDARD_NAME'] == 'ICD' + icd_version + 'CM'].dropna(subset=['CODE']).pivot(index='PMBB_ID', columns='CODE', values='condition_start_date').sort_index()
            ICD_counts = ICD[ICD['CODE_STANDARD_NAME'] == 'ICD' + icd_version + 'CM'].dropna(subset=['CODE']).pivot_table(index='PMBB_ID', columns='CODE', values='condition_start_date', aggfunc='count').sort_index().fillna(0)
            ICD_matrix = ICD_matrix.apply(lambda x: x - PMBB.loc[ICD_matrix.index, 'Birth_date_SHIFT'])
            ICD_matrix = ICD_matrix.applymap(lambda x: x.days / 365.25)
            ICD_matrix = ICD_matrix.sort_index()
            ICD_matrix = ICD_matrix.loc[ICD_matrix.index.intersection(PMBB.index)]
            if len(ICD_matrix) == 0:
                continue
            print(ICD_matrix)
            add_phenos_from_matrix('icd' + icd_version, ICD_matrix, icd_map, pheno_df, np, ICD_counts)

        PHECODE_matrix = PHECODE.dropna(subset=['phecode']).drop_duplicates(subset=['PMBB_ID', 'phecode']).pivot(index='PMBB_ID', columns='phecode', values='ENC_DATE_SHIFT').sort_index()
        PHECODE_counts = PHECODE.dropna(subset=['phecode']).pivot_table(index='PMBB_ID',columns='phecode',values='ENC_DATE_SHIFT',aggfunc='count').sort_index().fillna(0)
        PHECODE_matrix = PHECODE_matrix.apply(lambda x: x - PMBB.loc[PHECODE_matrix.index, 'Birth_date_SHIFT'])
        PHECODE_matrix = PHECODE_matrix.applymap(lambda x: x.days / 365.25)
        PHECODE_matrix = PHECODE_matrix.sort_index()
        PHECODE_matrix = PHECODE_matrix.loc[PHECODE_matrix.index.intersection(PMBB.index)]

        add_phenos_from_matrix('phecode', PHECODE_matrix, phecode_map, pheno_df, np, PHECODE_counts)

        all_pheno_cols = add_union_phenos(pheno_df, np)

        print(pheno_df)

        if 'AGE' in config['keep_covars']:
            pheno_df['ENROLLMENT_AGE'] = PMBB['Age_at_Enrollment']
            pheno_df['CURRENT_AGE'] = PMBB['CURRENT_AGE']
            for pheno in config['pheno_defs']:
                pheno_df['AGE_' + pheno] = pheno_df['ENROLLMENT_AGE'].copy()
                pheno_df['AGE_' + pheno].update(pheno_df[pheno + '_age@dx'])

        if 'SEX' in config['keep_covars']:
            pheno_df['SEX'] = PMBB['Sex']

        if 'BMI' in config['keep_covars']:
            print('Adding BMI...')
            bmi = pd.read_table(PMBB_BMI, nrows=None, parse_dates=['ENC_DATE_SHIFT'])
            bmi = bmi.sort_values(by='ENC_DATE_SHIFT')
            first_bmi = bmi.drop_duplicates(subset='PMBB_ID', keep='first').set_index('PMBB_ID')['BMI']
            first_bmi_date = bmi.drop_duplicates(subset='PMBB_ID', keep='first').set_index('PMBB_ID')['ENC_DATE_SHIFT']
            last_bmi = bmi.drop_duplicates(subset='PMBB_ID', keep='last').set_index('PMBB_ID')['BMI']
            last_bmi_date = bmi.drop_duplicates(subset='PMBB_ID', keep='last').set_index('PMBB_ID')['ENC_DATE_SHIFT']
            mean_bmi = bmi.groupby('PMBB_ID')['BMI'].mean()

            median_bmi = bmi.groupby('PMBB_ID')['BMI'].median()
            median_measurement = pd.Series(dtype=bool, index=bmi.index, data=False)
            for id, subDF in bmi.groupby('PMBB_ID'):
                subDF = subDF[subDF['BMI'] >= median_bmi.loc[id]].sort_values(by='BMI')
                median_measurement.loc[subDF.index[0]] = True

            median_bmi_date = bmi[median_measurement].set_index('PMBB_ID')['ENC_DATE_SHIFT']
            median_bmi_age = (median_bmi_date - PMBB.loc[median_bmi_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days / 365.25)

            pheno_df['BMI_first'] = first_bmi.reindex(pheno_df.index)
            pheno_df['BMI_first_AGE'] = (first_bmi_date - PMBB.loc[first_bmi_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days / 365.25).reindex(pheno_df.index)
            pheno_df['BMI_last'] = last_bmi.reindex(pheno_df.index)
            pheno_df['BMI_last_AGE'] = (last_bmi_date - PMBB.loc[last_bmi_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days / 365.25).reindex(pheno_df.index)
            pheno_df['BMI_mean'] = mean_bmi.reindex(pheno_df.index)
            pheno_df['BMI_median'] = median_bmi.reindex(pheno_df.index)
            pheno_df['BMI_median_AGE'] = median_bmi_age.reindex(pheno_df.index)

        if 'BP' in config['keep_covars']:
            print('Adding BP...')
            bmi = pd.read_table(PMBB_BP, nrows=None, parse_dates=['ENC_DATE_SHIFT'])
            bmi = bmi.sort_values(by='ENC_DATE_SHIFT')
            first_sys = bmi.drop_duplicates(subset='PMBB_ID', keep='first').set_index('PMBB_ID')['SYSTOLIC']
            first_dia = bmi.drop_duplicates(subset='PMBB_ID', keep='first').set_index('PMBB_ID')['DIASTOLIC']
            last_sys = bmi.drop_duplicates(subset='PMBB_ID', keep='last').set_index('PMBB_ID')['SYSTOLIC']
            last_dia = bmi.drop_duplicates(subset='PMBB_ID', keep='last').set_index('PMBB_ID')['DIASTOLIC']
            mean_sys = bmi.groupby('PMBB_ID')['SYSTOLIC'].mean()
            mean_dia = bmi.groupby('PMBB_ID')['DIASTOLIC'].mean()
            median_sys = bmi.groupby('PMBB_ID')['SYSTOLIC'].median()
            median_dia = bmi.groupby('PMBB_ID')['DIASTOLIC'].median()

            pheno_df['BP_SYSTOLIC_first'] = first_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_first'] = first_dia.reindex(pheno_df.index)
            pheno_df['BP_SYSTOLIC_last'] = last_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_last'] = last_dia.reindex(pheno_df.index)
            pheno_df['BP_SYSTOLIC_mean'] = mean_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_mean'] = mean_dia.reindex(pheno_df.index)
            pheno_df['BP_SYSTOLIC_median'] = median_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_median'] = median_dia.reindex(pheno_df.index)

        print(pheno_df)

        if config['keep_PCs'] > 0:
            keep_cols = ['Genotype_PC' + str(i) for i in range(1, min(11, config['keep_PCs'] + 1))]
            rename_cols = dict(zip(keep_cols, ['PC' + str(i) for i in range(1, min(11, config['keep_PCs'] + 1))]))
            pheno_df = pheno_df.merge(PMBB[keep_cols], left_index=True, right_index=True)
            pheno_df = pheno_df.rename(columns=rename_cols)

        ANC = pd.read_table(PMBB_ANC, index_col='PMBB_ID')
        pheno_df['ANCESTRY'] = ANC['Class']
        if len(config['ancestries']) <= 5:
            pheno_df = pheno_df[pheno_df['ANCESTRY'].isin(config['ancestries'])]
            
        print(pheno_df)

        pheno_df.index.name = 'PMBB_ID'
        for anc, subDF in pheno_df.groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[all_pheno_cols].apply(lambda x: x.fillna('NA').value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/PMBB_counts_' + anc + '.csv')


        relateds = open(PMBB_RELATEDS).read().splitlines()
        pheno_df['Related_to_Drop']  = 0
        pheno_df.loc[pheno_df.index.astype(str).isin(relateds), 'Related_to_Drop'] = 1

        print('')
        print(pheno_df)
        pheno_df.to_csv(output.pheno_table)

rule make_pmbb_23_pheno_covars:
    output:
        pheno_table='Pheno/PMBB_2.3_pheno_covars.csv',
        counts=expand('Pheno/PMBB_2.3_counts_{anc}.csv',anc=[a for a in config['ancestries'] if
                                                         a in ['EUR', 'AFR', 'EAS', 'SAS', 'AMR']]),
        maps=expand('Pheno/PMBB_2.3_{type}.json',type=['ICD_codes', 'phecodes']),
        pheno_table_long='Pheno/PMBB_2.3_phenotypes_long.csv'
    params:
        config['pheno_defs'],
        config['keep_covars'],
        config['keep_PCs'],
        config['ancestries']
    resources: mem_mb=12000
    run:
        import pandas as pd
        import numpy as np
        from datetime import datetime
        import json
        import sys

        print('Start')

        PMBB = pd.read_table(PMBB_COVAR,index_col='PMBB_ID',parse_dates=['Birth_date_SHIFT'],nrows=None)
        PMBB['CURRENT_AGE'] = (datetime(2023,6,1) - PMBB['Birth_date_SHIFT']).dt.days / 365.25
        print(PMBB)

        all_icd, all_icd_re = get_all_icd_codes()
        all_phecodes, all_phecode_re = get_all_phecodes()

        ICD = pd.read_table(PMBB_ICD_23,dtype={'CODE': str},parse_dates=['condition_start_date'],nrows=None)
        ICD = ICD[ICD['code_standard_name'] != 'None']
        PHECODE = pd.read_table(PMBB_PHECODE,dtype={'phecode': str},parse_dates=['ENC_DATE_SHIFT'],nrows=None)
        print(ICD)
        print(PHECODE)
        ICD = ICD.sort_values(by='condition_start_date')
        PHECODE = PHECODE.sort_values(by='ENC_DATE_SHIFT')

        last_ICD_date = ICD.drop_duplicates(subset='PMBB_ID',keep='last').set_index('PMBB_ID')['condition_start_date']
        ICD = ICD.drop_duplicates(subset=['PMBB_ID', 'code'],keep='first',ignore_index=True)
        PHECODE = PHECODE.drop_duplicates(subset=['PMBB_ID', 'phecode'],keep='first',ignore_index=True)
        print(ICD)
        print(PHECODE)

        ICD_new, icd_map = shorten_codes_long(ICD,all_icd_re,'code',np,all_icd)
        print(ICD_new)
        ICD = ICD_new.copy()

        PHECODE_new, phecode_map = shorten_codes_long(PHECODE,all_phecode_re,'phecode',np,all_phecodes)
        PHECODE = PHECODE_new.copy()
        print(ICD)
        print(PHECODE)
        json.dump(icd_map,open('Pheno/PMBB_2.3_ICD_codes.json','w+'))
        json.dump(phecode_map,open('Pheno/PMBB_2.3_phecodes.json','w+'))

        inverted_icd_map = {}
        for condition_code, codes in icd_map.items():
            conditions = []
            for condition, defs in config['pheno_defs'].items():
                if 'icd10_cases' in defs.keys():
                    case_codes = [c for c in defs['icd10_cases']]
                    if 'icd9_cases' in defs.keys():
                        case_codes.extend(defs['icd9_cases'])
                elif 'icd9_cases' in defs.keys():
                    case_codes = [c for c in defs['icd9_cases']]
                if condition_code in case_codes:
                    conditions.append(condition)
            conditions = ':'.join(conditions)
            for code in codes:
                if code not in inverted_icd_map.keys():
                    inverted_icd_map[code] = conditions
                else:
                    inverted_icd_map[code] += ':' + conditions

        ICD['ICD_CONDITIONS'] = ICD['code'].replace(inverted_icd_map)
        ICD['ICD_CONDITIONS'] = ICD['ICD_CONDITIONS'].mask(~ICD['code'].isin(inverted_icd_map.keys()))

        ICD['age_at_condition_start'] = (ICD['condition_start_date'] - PMBB.loc[ICD['PMBB_ID'], 'Birth_date_SHIFT'].values).apply(lambda x: x.days / 365.25)

        pd.concat([ICD, PHECODE]).to_csv(output.pheno_table_long,index=False)

        pheno_df = pd.DataFrame(index=PMBB.index)
        for icd_version in ['9', '10']:
            ICD_matrix = ICD[ICD['code_standard_name'] == 'ICD' + icd_version + 'CM'].dropna(subset=['code']).pivot(index='PMBB_ID',columns='code',values='condition_start_date').sort_index()
            ICD_counts = ICD[ICD['code_standard_name'] == 'ICD' + icd_version + 'CM'].dropna(subset=['code']).pivot_table(index='PMBB_ID',columns='code',values='condition_start_date',aggfunc='count').sort_index().fillna(0)
            ICD_matrix = ICD_matrix.apply(lambda x: x - PMBB.loc[ICD_matrix.index, 'Birth_date_SHIFT'])
            ICD_matrix = ICD_matrix.applymap(lambda x: x.days / 365.25)
            ICD_matrix = ICD_matrix.sort_index()
            ICD_matrix = ICD_matrix.loc[ICD_matrix.index.intersection(PMBB.index)]
            if len(ICD_matrix) == 0:
                continue
            print(ICD_matrix)
            add_phenos_from_matrix('icd' + icd_version,ICD_matrix,icd_map,pheno_df,np,ICD_counts)

        PHECODE_matrix = PHECODE.dropna(subset=['phecode']).drop_duplicates(subset=['PMBB_ID',
                                                                                    'phecode']).pivot(index='PMBB_ID',columns='phecode',values='ENC_DATE_SHIFT').sort_index()
        PHECODE_counts = PHECODE.dropna(subset=[
            'phecode']).pivot_table(index='PMBB_ID',columns='phecode',values='ENC_DATE_SHIFT',aggfunc='count').sort_index().fillna(0)
        PHECODE_matrix = PHECODE_matrix.apply(lambda x: x - PMBB.loc[PHECODE_matrix.index, 'Birth_date_SHIFT'])
        PHECODE_matrix = PHECODE_matrix.applymap(lambda x: x.days / 365.25)
        PHECODE_matrix = PHECODE_matrix.sort_index()
        PHECODE_matrix = PHECODE_matrix.loc[PHECODE_matrix.index.intersection(PMBB.index)]

        add_phenos_from_matrix('phecode',PHECODE_matrix,phecode_map,pheno_df,np,PHECODE_counts)

        all_pheno_cols = add_union_phenos(pheno_df,np)

        print(pheno_df)

        if 'AGE' in config['keep_covars']:
            pheno_df['ENROLLMENT_AGE'] = PMBB['Age_at_Enrollment']
            pheno_df['CURRENT_AGE'] = PMBB['CURRENT_AGE']
            for pheno in config['pheno_defs']:
                pheno_df['AGE_' + pheno] = pheno_df['ENROLLMENT_AGE'].copy()
                pheno_df['AGE_' + pheno].update(pheno_df[pheno + '_age@dx'])

        if 'SEX' in config['keep_covars']:
            pheno_df['SEX'] = PMBB['Sex']

        if 'BMI' in config['keep_covars']:
            print('Adding BMI...')
            bmi = pd.read_table(PMBB_BMI,nrows=None,parse_dates=['ENC_DATE_SHIFT'])
            bmi = bmi.sort_values(by='ENC_DATE_SHIFT')
            first_bmi = bmi.drop_duplicates(subset='PMBB_ID',keep='first').set_index('PMBB_ID')['BMI']
            first_bmi_date = bmi.drop_duplicates(subset='PMBB_ID',keep='first').set_index('PMBB_ID')['ENC_DATE_SHIFT']
            last_bmi = bmi.drop_duplicates(subset='PMBB_ID',keep='last').set_index('PMBB_ID')['BMI']
            last_bmi_date = bmi.drop_duplicates(subset='PMBB_ID',keep='last').set_index('PMBB_ID')['ENC_DATE_SHIFT']
            mean_bmi = bmi.groupby('PMBB_ID')['BMI'].mean()

            median_bmi = bmi.groupby('PMBB_ID')['BMI'].median()
            median_measurement = pd.Series(dtype=bool,index=bmi.index,data=False)
            for id, subDF in bmi.groupby('PMBB_ID'):
                subDF = subDF[subDF['BMI'] >= median_bmi.loc[id]].sort_values(by='BMI')
                median_measurement.loc[subDF.index[0]] = True

            median_bmi_date = bmi[median_measurement].set_index('PMBB_ID')['ENC_DATE_SHIFT']
            median_bmi_age = (median_bmi_date - PMBB.loc[
                median_bmi_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days / 365.25)

            pheno_df['BMI_first'] = first_bmi.reindex(pheno_df.index)
            pheno_df['BMI_first_AGE'] = (first_bmi_date - PMBB.loc[
                first_bmi_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days / 365.25).reindex(pheno_df.index)
            pheno_df['BMI_last'] = last_bmi.reindex(pheno_df.index)
            pheno_df['BMI_last_AGE'] = (last_bmi_date - PMBB.loc[
                last_bmi_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days / 365.25).reindex(pheno_df.index)
            pheno_df['BMI_mean'] = mean_bmi.reindex(pheno_df.index)
            pheno_df['BMI_median'] = median_bmi.reindex(pheno_df.index)
            pheno_df['BMI_median_AGE'] = median_bmi_age.reindex(pheno_df.index)

        if 'BP' in config['keep_covars']:
            print('Adding BP...')
            bmi = pd.read_table(PMBB_BP,nrows=None,parse_dates=['ENC_DATE_SHIFT'])
            bmi = bmi.sort_values(by='ENC_DATE_SHIFT')
            first_sys = bmi.drop_duplicates(subset='PMBB_ID',keep='first').set_index('PMBB_ID')['SYSTOLIC']
            first_dia = bmi.drop_duplicates(subset='PMBB_ID',keep='first').set_index('PMBB_ID')['DIASTOLIC']
            last_sys = bmi.drop_duplicates(subset='PMBB_ID',keep='last').set_index('PMBB_ID')['SYSTOLIC']
            last_dia = bmi.drop_duplicates(subset='PMBB_ID',keep='last').set_index('PMBB_ID')['DIASTOLIC']
            mean_sys = bmi.groupby('PMBB_ID')['SYSTOLIC'].mean()
            mean_dia = bmi.groupby('PMBB_ID')['DIASTOLIC'].mean()
            median_sys = bmi.groupby('PMBB_ID')['SYSTOLIC'].median()
            median_dia = bmi.groupby('PMBB_ID')['DIASTOLIC'].median()

            pheno_df['BP_SYSTOLIC_first'] = first_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_first'] = first_dia.reindex(pheno_df.index)
            pheno_df['BP_SYSTOLIC_last'] = last_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_last'] = last_dia.reindex(pheno_df.index)
            pheno_df['BP_SYSTOLIC_mean'] = mean_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_mean'] = mean_dia.reindex(pheno_df.index)
            pheno_df['BP_SYSTOLIC_median'] = median_sys.reindex(pheno_df.index)
            pheno_df['BP_DIASTOLIC_median'] = median_dia.reindex(pheno_df.index)

        print(pheno_df)

        if config['keep_PCs'] > 0:
            keep_cols = ['Genotype_PC' + str(i) for i in range(1,min(11,config['keep_PCs'] + 1))]
            rename_cols = dict(zip(keep_cols,['PC' + str(i) for i in range(1,min(11,config['keep_PCs'] + 1))]))
            pheno_df = pheno_df.merge(PMBB[keep_cols],left_index=True,right_index=True)
            pheno_df = pheno_df.rename(columns=rename_cols)

        ANC = pd.read_table(PMBB_ANC,index_col='PMBB_ID')
        pheno_df['ANCESTRY'] = ANC['Class']
        if len(config['ancestries']) <= 5:
            pheno_df = pheno_df[pheno_df['ANCESTRY'].isin(config['ancestries'])]

        print(pheno_df)

        pheno_df.index.name = 'PMBB_ID'
        for anc, subDF in pheno_df.groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[all_pheno_cols].apply(lambda x: x.fillna(-1).value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/PMBB_2.3_counts_' + anc + '.csv')

        relateds = open(PMBB_RELATEDS).read().splitlines()
        pheno_df['Related_to_Drop'] = 0
        pheno_df.loc[pheno_df.index.astype(str).isin(relateds), 'Related_to_Drop'] = 1

        print('')
        print(pheno_df)
        pheno_df.to_csv(output.pheno_table)

rule make_ukbb_pheno_covars:
    output:
        pheno_table='Pheno/UKBB_pheno_covars.csv',
        counts=expand('Pheno/UKBB_counts_{anc}.csv', anc=[a for a in config['ancestries'] if a in ['EUR', 'AFR', 'ASIAN']]),
        maps=expand('Pheno/UKBB_{type}.json', type=['ICD_codes', 'phecodes']),
        pheno_table_long='Pheno/UKBB_phenotypes_long.csv'
    params:
        config['pheno_defs'],
        config['keep_covars'],
        config['keep_PCs'],
        config['ancestries']
    resources: mem_mb=16000
    run:
        import pandas as pd
        import numpy as np
        import json
        import sys

        print('Start')

        # 22006 GIA, 22009 PCs

        cols = ['f.eid', 'f.31.0.0', 'f.21000.0.0', 'f.21001.0.0', 'f.21022.0.0', 'f.22006.0.0', 'f.22021.0.0']
        cols.extend(['f.22009.0.' + str(i) for i in range(1, config['keep_PCs'] + 1)])

        UKBB = pd.read_table(UKBB_FIELDS, index_col='f.eid', usecols=cols, sep='\t', nrows=None)

        col_map = {'f.31.0.0': 'SEX', 'f.21000.0.0': 'ETH', 'f.21001.0.0': 'BMI', 'f.21022.0.0': 'AGE', 'f.22006.0.0': 'GIA', 'f.22021.0.0': 'KINSHIP'}
        for i in range(1, config['keep_PCs']+1):
            col_map['f.22009.0.' + str(i)] = 'PC' + str(i)

        UKBB = UKBB.rename(columns=col_map)
        print(UKBB)

        all_icd, all_icd_re = get_all_icd_codes(ukbb=True)

        ICD9 = pd.read_table(UKBB_ICD9, dtype={'icd9': str}, sep=' ', nrows=None)
        ICD10 = pd.read_table(UKBB_ICD10, dtype={'icd10': str}, sep=' ', nrows=None)
        print(ICD9)
        print(ICD10)

        ICD9 = ICD9.drop_duplicates(subset=['f.eid', 'icd9'], keep='first', ignore_index=True)
        ICD10 = ICD10.drop_duplicates(subset=['f.eid', 'icd10'], keep='first', ignore_index=True)

        ICD9, icd9_map = shorten_codes_long(ICD9, all_icd_re, 'icd9', np, all_icd)
        ICD10, icd10_map = shorten_codes_long(ICD10, all_icd_re, 'icd10', np, all_icd)

        icd_map = {}
        for k, v in icd9_map.items():
            icd_map[k] = v
        for k, v in icd10_map.items():
            icd_map[k] = v

        phecode_map = {}
        json.dump(icd_map, open('Pheno/UKBB_ICD_codes.json','w+'))
        json.dump(phecode_map, open('Pheno/UKBB_phecodes.json','w+'))

        inverted_icd_map = {}
        for condition_code, codes in icd_map.items():
            conditions = []
            for condition, defs in config['pheno_defs'].items():
                if 'icd10_cases' in defs.keys():
                    case_codes = [c for c in defs['icd10_cases']]
                    if 'icd9_cases' in defs.keys():
                        case_codes.extend(defs['icd9_cases'])
                elif 'icd9_cases' in defs.keys():
                    case_codes = [c for c in defs['icd9_cases']]
                if condition_code in case_codes:
                    conditions.append(condition)
            conditions = ':'.join(conditions)
            for code in codes:
                if code not in inverted_icd_map.keys():
                    inverted_icd_map[code] = conditions
                else:
                    inverted_icd_map[code] += ':' + conditions

        ICD9['ICD_CONDITIONS'] = ICD9['icd9'].replace(inverted_icd_map)
        ICD9['ICD_CONDITIONS'] = ICD9['ICD_CONDITIONS'].mask(~ICD9['icd9'].isin(inverted_icd_map.keys()))
        ICD10['ICD_CONDITIONS'] = ICD10['icd10'].replace(inverted_icd_map)
        ICD10['ICD_CONDITIONS'] = ICD10['ICD_CONDITIONS'].mask(~ICD10['icd10'].isin(inverted_icd_map.keys()))
        pd.concat([ICD9, ICD10]).to_csv(output.pheno_table_long, index=False)

        pheno_df = pd.DataFrame(index=UKBB.index)
        ICD9_matrix = ICD9.dropna(subset=['icd9']).pivot(index='f.eid', columns='icd9', values='f.34.0.0').sort_index()
        ICD9_counts = ICD9.dropna(subset=['icd9']).pivot_table(index='f.eid', columns='icd9', values='f.34.0.0', aggfunc='count').sort_index().fillna(0)
        ICD9_matrix = ICD9_matrix.sort_index()
        ICD9_matrix = ICD9_matrix.loc[ICD9_matrix.index.intersection(UKBB.index)]
        ICD9_counts = ICD9_counts.loc[ICD9_counts.index.intersection(UKBB.index)]
        add_phenos_from_matrix('icd9', ICD9_matrix, icd_map, pheno_df, np, ICD9_counts)

        ICD10_matrix = ICD10.dropna(subset=['icd10']).pivot(index='f.eid', columns='icd10', values='f.34.0.0').sort_index()
        ICD10_counts = ICD10.dropna(subset=['icd10']).pivot_table(index='f.eid', columns='icd10', values='f.34.0.0', aggfunc='count').sort_index().fillna(0)
        ICD10_matrix = ICD10_matrix.sort_index()
        ICD10_matrix = ICD10_matrix.loc[ICD10_matrix.index.intersection(UKBB.index)]
        ICD10_counts = ICD10_counts.loc[ICD10_counts.index.intersection(UKBB.index)]
        add_phenos_from_matrix('icd10', ICD10_matrix, icd_map, pheno_df, np, ICD10_counts)

        all_pheno_cols = add_union_phenos(pheno_df, np)
        pheno_df = pheno_df[[c for c in pheno_df.columns if '_age@dx' not in c]]
        print(pheno_df)

        if 'AGE' in config['keep_covars']:
            pheno_df['AGE'] = UKBB['AGE']

        if 'SEX' in config['keep_covars']:
            pheno_df['SEX'] = UKBB['SEX'].replace({0: 'Female', 1: 'Male'})

        if config['keep_PCs'] > 0:
            keep_cols = ['PC' + str(i) for i in range(1,min(11,config['keep_PCs'] + 1))]
            PCs = UKBB[keep_cols]
            pheno_df = pd.concat([pheno_df, PCs], axis=1)

        if 'BMI' in config['keep_covars']:
            pheno_df['BMI'] = UKBB['BMI']

        pheno_df['ANCESTRY'] = UKBB['ETH'].replace({1001: 'EUR', 1002: 'EUR', 1003: 'EUR',
                                                    4001: 'AFR', 4002: 'AFR', 4003: 'AFR',
                                                    3001: 'ASIAN', 3002: 'ASIAN', 3003: 'ASIAN', 3004: 'ASIAN'})
        pheno_df = pheno_df[pheno_df['ANCESTRY'].isin(config['ancestries'])]
        print(pheno_df)

        pheno_df['ETH'] = UKBB['ETH']
        pheno_df['GIA'] = UKBB['GIA']
        pheno_df['KINSHIP'] = UKBB['KINSHIP']

        pheno_df.index.name = 'f.eid'
        for anc, subDF in pheno_df[pheno_df.ANCESTRY.isin(config['ancestries'])].groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[all_pheno_cols].apply(lambda x: x.fillna('NA').value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/UKBB_counts_' + anc + '.csv')

        print('')
        print(pheno_df)
        pheno_df.to_csv(output.pheno_table)
def get_all_procedure_codes():
    codes = []
    for procedure in config['procedures_cpt4']:
        codes.extend(config['procedures_cpt4'][procedure])

    codes = [str(c) for c in codes]
    codes = list(set(codes))
    return codes

rule make_pmbb_procedures:
    output:
        procedure_table='Pheno/PMBB_procedures.csv',
        counts=expand('Pheno/PMBB_procedure_counts_{anc}.csv', anc=[a for a in config['ancestries'] if a in ['EUR', 'AFR', 'EAS', 'SAS', 'AMR']]),
        procedure_table_long='Pheno/PMBB_procedures_long.csv'
    params:
        config['procedures_cpt4'],
        config['ancestries']
    resources: mem_mb=12000
    run:
        import pandas as pd

        print('Start')

        PMBB = pd.read_table(PMBB_COVAR, index_col='PMBB_ID', parse_dates=['Birth_date_SHIFT'], dtype={'CODE': str})
        print(PMBB)

        all_procedure_codes = get_all_procedure_codes()
        procedures = pd.read_table(PMBB_PROCEDURES, parse_dates=['ENC_DATE_SHIFT'], nrows=None)
        print(procedures.dtypes['CODE'])
        # procedures = procedures[procedures['CODE_STANDARD_NAME'] == 'CPT4']
        # procedures = procedures[procedures['ENC_TYPE_CODE'] == 'Procedure']
        procedures = procedures[procedures['CODE'].isin(all_procedure_codes)]
        procedures = procedures[procedures['PMBB_ID'].isin(PMBB.index)]
        print(procedures)
        print(all_procedure_codes)

        inverted_procedure_map = {}
        for procedure, codes in config['procedures_cpt4'].items():
            print(procedure, codes)
            for code in codes:
                if str(code) not in inverted_procedure_map.keys():
                    inverted_procedure_map[str(code)] = procedure
                else:
                    inverted_procedure_map[str(code)] += ':' + procedure

        procedures['CPT_PROCEDURE'] = procedures['CODE'].replace(inverted_procedure_map)
        procedures.to_csv(output.procedure_table_long, index=False)

        print(procedures.drop_duplicates(subset=['PMBB_ID', 'CODE']))

        procedure_mtx = procedures.drop_duplicates(subset=['PMBB_ID', 'CODE']).pivot(index='PMBB_ID', columns='CODE', values='ENC_DATE_SHIFT')
        print(procedure_mtx)

        procedure_df = pd.DataFrame(index=PMBB.index)

        for procedure, codes in config['procedures_cpt4'].items():
            codes = [str(c) for c in codes if str(c) in procedure_mtx.columns]
            if len(codes) == 0:
                continue
            procedure_date = procedure_mtx[codes].min(axis=1)
            procedure_binary = (~pd.isnull(procedure_date)).astype(int)
            procedure_age = (procedure_date - PMBB.loc[procedure_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days) / 365.25

            procedure_df[procedure] = procedure_binary.reindex(procedure_df.index).fillna(0).astype(int)
            procedure_df[procedure + '_age'] = procedure_age.reindex(procedure_df.index)
            procedure_df[procedure + '_date'] = procedure_date.reindex(procedure_df.index)

        ANC = pd.read_table(PMBB_ANC, index_col='PMBB_ID')
        procedure_df['ANCESTRY'] = ANC['Class']
        procedure_df = procedure_df[procedure_df['ANCESTRY'].isin(config['ancestries'])]
        print(procedure_df)

        procedure_df.index.name = 'PMBB_ID'
        procedure_cols = [p for p in config['procedures_cpt4'].keys() if p in procedure_df.columns]
        for anc, subDF in procedure_df.groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[procedure_cols].apply(lambda x: x.fillna('NA').value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/PMBB_procedure_counts_' + anc + '.csv')

        print('')
        print(procedure_df)
        procedure_df.to_csv(output.procedure_table)

rule make_pmbb_23_procedures:
    output:
        procedure_table='Pheno/PMBB_2.3_procedures.csv',
        counts=expand('Pheno/PMBB_2.3_procedure_counts_{anc}.csv', anc=[a for a in config['ancestries'] if a in ['EUR', 'AFR', 'EAS', 'SAS', 'AMR']]),
        procedure_table_long='Pheno/PMBB_2.3_procedures_long.csv'
    params:
        config['procedures_cpt4'],
        config['ancestries']
    resources: mem_mb=12000
    run:
        import pandas as pd

        print('Start')

        PMBB = pd.read_table(PMBB_COVAR, index_col='PMBB_ID', parse_dates=['Birth_date_SHIFT'], dtype={'CODE': str})
        print(PMBB)

        all_procedure_codes = get_all_procedure_codes()
        procedures = pd.read_table(PMBB_PROCEDURES_23, parse_dates=['enc_date_shift'], nrows=None)
        procedures['age_at_enc'] = (procedures['enc_date_shift'] - PMBB.loc[procedures['PMBB_ID'], 'Birth_date_SHIFT'].values).apply(lambda x: x.days / 365.25)
        print(procedures.columns)
        print(procedures.dtypes['code'])
        # procedures = procedures[procedures['CODE_STANDARD_NAME'] == 'CPT4']
        # procedures = procedures[procedures['ENC_TYPE_CODE'] == 'Procedure']
        procedures = procedures[procedures['code'].isin(all_procedure_codes)]
        procedures = procedures[procedures['PMBB_ID'].isin(PMBB.index)]
        print(procedures)
        print(all_procedure_codes)

        inverted_procedure_map = {}
        for procedure, codes in config['procedures_cpt4'].items():
            print(procedure, codes)
            for code in codes:
                if str(code) not in inverted_procedure_map.keys():
                    inverted_procedure_map[str(code)] = procedure
                else:
                    inverted_procedure_map[str(code)] += ':' + procedure

        procedures['CPT_PROCEDURE'] = procedures['code'].replace(inverted_procedure_map)
        procedures.to_csv(output.procedure_table_long, index=False)

        print(procedures.drop_duplicates(subset=['PMBB_ID', 'code']))

        procedure_mtx = procedures.drop_duplicates(subset=['PMBB_ID', 'code']).pivot(index='PMBB_ID', columns='code', values='enc_date_shift')
        print(procedure_mtx)

        procedure_df = pd.DataFrame(index=PMBB.index)

        for procedure, codes in config['procedures_cpt4'].items():
            codes = [str(c) for c in codes if str(c) in procedure_mtx.columns]
            if len(codes) == 0:
                continue
            procedure_date = procedure_mtx[codes].min(axis=1)
            procedure_binary = (~pd.isnull(procedure_date)).astype(int)
            procedure_age = (procedure_date - PMBB.loc[procedure_date.index, 'Birth_date_SHIFT']).apply(lambda x: x.days) / 365.25

            procedure_df[procedure] = procedure_binary.reindex(procedure_df.index).fillna(0).astype(int)
            procedure_df[procedure + '_age'] = procedure_age.reindex(procedure_df.index)
            procedure_df[procedure + '_date'] = procedure_date.reindex(procedure_df.index)

        ANC = pd.read_table(PMBB_ANC, index_col='PMBB_ID')
        procedure_df['ANCESTRY'] = ANC['Class']
        procedure_df = procedure_df[procedure_df['ANCESTRY'].isin(config['ancestries'])]
        print(procedure_df)

        procedure_df.index.name = 'PMBB_ID'
        procedure_cols = [p for p in config['procedures_cpt4'].keys() if p in procedure_df.columns]
        for anc, subDF in procedure_df.groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[procedure_cols].apply(lambda x: x.fillna('NA').value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/PMBB_2.3_procedure_counts_' + anc + '.csv')

        print('')
        print(procedure_df)
        procedure_df.to_csv(output.procedure_table)

rule make_emerge_procedures:
    output:
        procedure_table='Pheno/eMERGE_procedures.csv',
        counts=expand('Pheno/eMERGE_procedure_counts_{anc}.csv', anc=[a for a in config['ancestries'] if a in ['EUR', 'AFR', 'ASIAN']]),
        procedure_table_long='Pheno/eMERGE_procedures_long.csv'
    params:
        config['procedures_cpt4'],
        config['ancestries']
    resources: mem_mb=12000
    run:
        import pandas as pd
        import numpy as np
        import sys

        print('Start')

        eMERGE = pd.read_csv(EMERGE_DEMO, index_col='SUBJECT_ID')
        print(eMERGE)

        all_procedure_codes = get_all_procedure_codes()

        chunks = []
        for chunk in pd.read_csv(EMERGE_PROCEDURES, chunksize=2E6):
            chunk = chunk[chunk['CPT_CODE'].isin(all_procedure_codes)]
            chunk = chunk[chunk['SUBJID'].isin(eMERGE.index)]
            chunk['AGE_AT_EVENT'] = pd.to_numeric(chunk['AGE_AT_EVENT'], errors='coerce')
            chunk = chunk.dropna(subset=['AGE_AT_EVENT'])
            chunks.append(chunk)
            print(len(chunks))

        procedures = pd.concat(chunks)
        print(procedures)
        procedures = procedures.sort_values(by='AGE_AT_EVENT')
        print(procedures)
        print(all_procedure_codes)

        inverted_procedure_map = {}
        for procedure, codes in config['procedures_cpt4'].items():
            print(procedure, codes)
            for code in codes:
                if str(code) not in inverted_procedure_map.keys():
                    inverted_procedure_map[str(code)] = procedure
                else:
                    inverted_procedure_map[str(code)] += ':' + procedure

        procedures['CPT_PROCEDURE'] = procedures['CPT_CODE'].replace(inverted_procedure_map)
        procedures.to_csv(output.procedure_table_long, index=False)

        print(procedures.drop_duplicates(subset=['SUBJID', 'CPT_CODE'], keep='first'))

        procedure_mtx = procedures.drop_duplicates(subset=['SUBJID', 'CPT_CODE'], keep='first').pivot(index='SUBJID', columns='CPT_CODE', values='AGE_AT_EVENT')
        procedure_counts = procedures.pivot_table(index='SUBJID', columns='CPT_CODE', values='AGE_AT_EVENT', aggfunc='count')
        print(procedure_counts)
        print(procedure_mtx)

        procedure_df = pd.DataFrame(index=eMERGE.index)
        print(procedure_df)

        for procedure, codes in config['procedures_cpt4'].items():
            codes = [str(c) for c in codes if str(c) in procedure_mtx.columns]
            if len(codes) == 0:
                continue
            print(codes)
            procedure_age = procedure_mtx[codes].min(axis=1)
            print(procedure_age)
            procedure_binary = (~pd.isnull(procedure_age)).astype(int)
            print(procedure_binary)

            procedure_df[procedure] = procedure_binary.reindex(procedure_df.index).fillna(0).astype(int)
            procedure_df[procedure + '_age'] = procedure_age.reindex(procedure_df.index)
            procedure_df[procedure + '_count'] = procedure_counts[codes].sum(axis=1)

        print(procedure_df)
        suffix_map = {'AFR': 'african', 'EUR': 'european', 'ASIAN': 'asian'}
        procedure_df['ANCESTRY'] = np.nan
        for ancestry in config['ancestries']:
            if ancestry in suffix_map.keys():
                suffix = suffix_map[ancestry]
                ids = [int(i) for i in open(EMERGE_ANC_PREFIX + suffix, 'r').read().splitlines()]
                procedure_df.loc[procedure_df.index.intersection(ids), 'ANCESTRY'] = ancestry

        procedure_df = procedure_df[procedure_df['ANCESTRY'].isin(config['ancestries'])]

        procedure_df.index.name = 'SUBJID'
        procedure_cols = [p for p in config['procedures_cpt4'].keys() if p in procedure_df.columns]
        for anc, subDF in procedure_df.groupby('ANCESTRY'):
            print('\n')
            print(anc)
            counts = subDF[procedure_cols].apply(lambda x: x.fillna('NA').value_counts()).transpose()
            print(counts)
            counts.to_csv('Pheno/eMERGE_procedure_counts_' + anc + '.csv')

        print('')
        print(procedure_df)
        procedure_df.to_csv(output.procedure_table)

rule make_pmbb_labs:
    output:
        table='Pheno/PMBB_labs.csv'
    input:
        all_labs=expand(PMBB_LABS_PREFIX + '{lab}.txt', lab=config['lab_list'])
    params:
        lab_list=config['lab_list']
    resources: mem_mb=8000
    run:
        import pandas as pd

        cov = pd.read_table(PMBB_COVAR, index_col='PMBB_ID')
        labs = pd.DataFrame(index=cov.index)

        for lab in input.all_labs:
            labs_temp = pd.read_table(lab, index_col='PMBB_ID', parse_dates=['RESULT_DATE_SHIFT']).sort_values(by='RESULT_DATE_SHIFT')
            lab_name = lab.replace(PMBB_LABS_PREFIX, '').replace('.txt', '')
            print(lab_name)
            labs[lab_name + '_Median'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].median()
            labs[lab_name + '_Mean'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].mean()
            labs[lab_name + '_First'] = labs_temp[~labs_temp.index.duplicated(keep='first')]['RESULT_VALUE_NUM']
            labs[lab_name + '_Last'] = labs_temp[~labs_temp.index.duplicated(keep='last')]['RESULT_VALUE_NUM']
            labs[lab_name + '_Min'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].min()
            labs[lab_name + '_Max'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].max()
            labs[lab_name + '_Abnormal_Count'] = labs_temp.groupby(labs_temp.index)['ABNORMAL'].count()
            labs[lab_name + '_Measurement_Count'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].count()


        print('Sample Sizes:')
        print(labs.count()[labs.count().index.to_series().str.contains('Mean')])

        labs.to_csv(output.table)

        print('End')

rule make_pmbb_23_labs:
    output:
        table='Pheno/PMBB_2.3_labs.csv'
    input:
        all_labs=expand(PMBB_LABS_PREFIX_23 + '{lab}.txt', lab=config['lab_list'])
    params:
        lab_list=config['lab_list']
    resources: mem_mb=8000
    run:
        import pandas as pd

        cov = pd.read_table(PMBB_COVAR, index_col='PMBB_ID')
        labs = pd.DataFrame(index=cov.index)

        for lab in input.all_labs:
            labs_temp = pd.read_table(lab, index_col='PMBB_ID', parse_dates=['RESULT_DATE_SHIFT']).sort_values(by='RESULT_DATE_SHIFT')
            lab_name = lab.replace(PMBB_LABS_PREFIX_23, '').replace('.txt', '')
            print(lab_name)
            if lab_name == 'eGFR':
                labs[lab_name + '_Median'] = labs_temp.groupby(labs_temp.index)['eGFR'].median()
                labs[lab_name + '_Mean'] = labs_temp.groupby(labs_temp.index)['eGFR'].mean()
                labs[lab_name + '_First'] = labs_temp[~labs_temp.index.duplicated(keep='first')]['eGFR']
                labs[lab_name + '_Last'] = labs_temp[~labs_temp.index.duplicated(keep='last')]['eGFR']
                labs[lab_name + '_Min'] = labs_temp.groupby(labs_temp.index)['eGFR'].min()
                labs[lab_name + '_Max'] = labs_temp.groupby(labs_temp.index)['eGFR'].max()
                labs[lab_name + '_Measurement_Count'] = labs_temp.groupby(labs_temp.index)['eGFR'].count()
            else:
                labs[lab_name + '_Median'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].median()
                labs[lab_name + '_Mean'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].mean()
                labs[lab_name + '_First'] = labs_temp[~labs_temp.index.duplicated(keep='first')]['RESULT_VALUE_NUM']
                labs[lab_name + '_Last'] = labs_temp[~labs_temp.index.duplicated(keep='last')]['RESULT_VALUE_NUM']
                labs[lab_name + '_Min'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].min()
                labs[lab_name + '_Max'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].max()
                labs[lab_name + '_Abnormal_Count'] = labs_temp.groupby(labs_temp.index)['ABNORMAL'].count()
                labs[lab_name + '_Measurement_Count'] = labs_temp.groupby(labs_temp.index)['RESULT_VALUE_NUM'].count()

        print('Sample Sizes:')
        print(labs.count()[labs.count().index.to_series().str.contains('Mean')])

        labs.to_csv(output.table)

        print('End')

rule make_emerge_labs:
    output:
        table='Pheno/eMERGE_labs.csv'
    input:
        all_labs=expand(EMERGE_LABS_PREFIX + '{lab}.csv', lab=config['lab_list'])
    params:
        lab_list=config['lab_list']
    resources: mem_mb=8000
    run:
        import pandas as pd
        import numpy as np

        cov = pd.read_csv(EMERGE_DEMO, index_col='SUBJECT_ID')
        cov.index.name = 'SUBJID'
        labs = pd.DataFrame(index=cov.index)

        for lab in input.all_labs:
            labs_temp = pd.read_csv(lab, index_col='SUBJID').sort_values(by='AGE_AT_EVENT')
            labs_temp['ABNORMAL'] = np.nan
            labs_temp.loc[labs_temp['ABNORMAL_LOW'], 'ABNORMAL'] = 'Low'
            labs_temp.loc[labs_temp['ABNORMAL_HIGH'], 'ABNORMAL'] = 'High'
            lab_name = lab.replace(EMERGE_LABS_PREFIX, '').replace('.csv', '')
            print(lab_name)
            labs[lab_name + '_Median'] = labs_temp.groupby(labs_temp.index)['VALUE_AS_NUMBER'].median()
            labs[lab_name + '_Mean'] = labs_temp.groupby(labs_temp.index)['VALUE_AS_NUMBER'].mean()
            labs[lab_name + '_First'] = labs_temp[~labs_temp.index.duplicated(keep='first')]['VALUE_AS_NUMBER']
            labs[lab_name + '_Last'] = labs_temp[~labs_temp.index.duplicated(keep='last')]['VALUE_AS_NUMBER']
            labs[lab_name + '_Min'] = labs_temp.groupby(labs_temp.index)['VALUE_AS_NUMBER'].min()
            labs[lab_name + '_Max'] = labs_temp.groupby(labs_temp.index)['VALUE_AS_NUMBER'].max()
            labs[lab_name + '_Abnormal_Count'] = labs_temp.groupby(labs_temp.index)['ABNORMAL'].count()
            labs[lab_name + '_Measurement_Count'] = labs_temp.groupby(labs_temp.index)['VALUE_AS_NUMBER'].count()


        print('Sample Sizes:')
        print(labs.count()[labs.count().index.to_series().str.contains('Mean')])

        labs.to_csv(output.table)

        print('End')

